Absolutely. Below is a **single, high-quality Replit AI prompt** designed specifically to generate a **working audio-reactive visualization web app** (not a toy demo).

You can paste this **directly into Replit AI / Replit Agent**.

---

## ğŸ”¥ REPLIT AI MASTER PROMPT

*(Audio-Reactive Visualization Web App)*

> **Role:**
> You are a senior creative-coding engineer and product engineer.
>
> **Goal:**
> Build a production-ready web app that allows users to upload an audio track and generates real-time, high-quality, audio-reactive visualizations in the browser.
>
> **Core Requirements:**
>
> 1. Create a **React + Vite** web app (no Next.js).
> 2. Use **Web Audio API** to analyze uploaded audio files (mp3, wav, ogg).
> 3. Extract **frequency bands** (bass, mid, high) and overall energy in real time.
> 4. Render visuals using **Three.js (WebGL)**, not 2D canvas.
> 5. Visuals must respond differently to:
>
>    * Bass â†’ scale / expansion
>    * Mid â†’ rotation / deformation
>    * High â†’ brightness / particle activity
> 6. Implement **3 visual presets**:
>
>    * â€œEnergy Ringsâ€
>    * â€œPsy Tunnelâ€
>    * â€œParticle Fieldâ€
> 7. Add UI controls:
>
>    * Upload audio
>    * Play / pause
>    * Intensity slider
>    * Motion speed slider
>    * Color palette selector
>    * Preset selector
> 8. Use **GPU shaders (GLSL)** where appropriate for smooth psychedelic motion.
> 9. Ensure visuals run at **60 FPS** on modern browsers.
>
> **Export Requirement:**
> Add a basic **record/export** feature that records the Three.js canvas and audio together and downloads a **WebM video**.
>
> **UX Requirements:**
>
> * Minimal, dark UI
> * Full-screen visuals
> * Instant feedback after upload
> * Clean component structure
>
> **Code Quality:**
>
> * Modular components
> * Clear comments
> * No placeholder logic
> * Avoid deprecated APIs
>
> **Deliverables:**
>
> * Full project file structure
> * Working code for audio analysis
> * Three.js visual engine
> * UI controls
> * Recording logic
> * Instructions to run locally
>
> **Do NOT:**
>
> * Use external visualizer libraries
> * Use template generators
> * Hardcode fake animations
>
> **Outcome:**
> A real audio-reactive visualization engine suitable as V1 of a next-gen music visualization platform.

---

## ğŸ§  OPTIONAL FOLLOW-UP PROMPTS (USE AFTER FIRST BUILD)

### ğŸ›ï¸ Improve Visual Quality

```
Refactor the visuals to use custom GLSL shaders for smoother psychedelic motion. Increase depth, glow, and fluidity.
```

### ğŸ§˜ Healing Mode (V2)

```
Add a "Healing Mode" where BPM controls slow breathing-like expansion and colors shift smoothly based on low-frequency dominance.
```

### ğŸ“± Mobile Optimization

```
Optimize the Three.js renderer for mobile performance and add touch-based interaction.
```

---

## âš ï¸ IMPORTANT TIP (REALITY CHECK)

Replit AI may:

* Get **audio analysis right**
* Get **Three.js basics right**
* Need **1â€“2 refinement passes** for shaders & performance

Thatâ€™s normal.

Use:

* **Replit AI â†’ structure + logic**
* **Cursor â†’ shader polish**
* **Your vision â†’ final tuning**

---

## ğŸš€ NEXT (if you want)

I can:

* Break this into **step-by-step Replit prompts**
* Generate a **fallback simpler prompt** (if AI struggles)
* Help you debug Replitâ€™s output live
* Convert this into a **Unity or WebGPU version**

Just tell me what you want to do next.
